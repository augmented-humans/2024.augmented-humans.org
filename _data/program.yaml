page-title: <strong>P</strong>rogram

#
#program-title: Program
#program-description: |
#    Last updated on March 13th
#    <br/>
#
#    <a href="../img/print/AHs2022Program.pdf" class="btn btn-md" style="background-color: #FFC847; border: 2px solid #F4FDD9; color: black !important; margin-top: 25px;" onMouseOver="this.style['background-color']='#E05263'" onMouseOut="this.style['background-color']='#FFC847'">Download PDF</a>

program-title: Program Schedule
program: The schedule of the sessions themselves can be found directly below.

sessions:
  - session: "Session 1: Haptic Feedback"
    papers:
    - title: 'Designing Interactive Shoes for Tactile Augmented Reality'
      authors: "Dennis Wittchen et al."
      doi: 'https://doi.org/10.1145/3582700.3582728'
      time: '11:30 - 11:45'
    - title: 'GAuze-MIcrosuture-FICATION: Gamification in Microsuture training with real-time feedback'
      authors: 'Yuka Tashiro et al.'
      doi: 'https://doi.org/10.1145/3582700.3582704'
      time: '11:45 - 12:00'
    - title: 'Standing Balance Improved by Electrical Muscle Stimulation to Popliteus Muscles'
      authors: 'Masato Shindo et al.'
      doi: 'https://doi.org/10.1145/3582700.3582711'
      time: '12:00 - 12:15'
    - title: 'Tactile Vectors for Omnidirectional Arm Guidance'
      authors: 'Hesham Elsayed et al.'
      doi: 'https://doi.org/10.1145/3582700.3582701'
      time: '12:15 - 12:30'
    - title: 'Coldness Presentation to Ventral Forearm using Electrical Stimulation with Elastic Gel and Anesthetic Cream'
      authors: 'Taiga  Saito et al.'
      doi: 'https://doi.org/10.1145/3582700.3582713'
      time: '12:30 - 12:45'
    - title: 'Q&A'
      time: '12:45 - 13:00'

  - session: "Session 2: Perception and Extended Reality"
    papers:
    - title: 'Virtual Omnibus Lecture: Investigating the Effects of Varying Lecturer Avatars as Environmental Context on Audience Memory'
      authors: 'Takato Mizuho et al.'
      doi: 'https://doi.org/10.1145/3582700.3582709'
      time: '14:15 - 14:30'
    - title: 'LocatAR: An AR Object Search Assistance System for a Shared Space'
      authors: 'Hiroto Oshimi et al.'
      doi: 'https://doi.org/10.1145/3582700.3582712'
      time: '14:30 - 14:45'
    - title: 'Generation of realistic facial animation of a CG avatar speaking a moraic language'
      authors: 'Yusuke Kikuchi et al.'
      doi: 'https://doi.org/10.1145/3582700.3582705'
      time: '14:45 - 15:00'
    - title: 'Effect of Weight Adjustment in Virtual Co-embodiment During Collaborative Training'
      authors: 'Daiki Kodama et al.'
      doi: 'https://doi.org/10.1145/3582700.3582703'
      time: '15:00 - 15:15'
    - title: 'Workspace Scaling in Virtual Reality based Robot Teleoperation'
      authors: 'Bukeikhan Omarali et al.'
      doi: 'https://doi.org/10.1145/3582700.3582717'
      time: '15:15 - 15:25'
    - title: 'Tablet Cutting Board: Tablet-based Knife-control Support System for Cookery Beginners'
      authors: 'Hatsune Masuda et al.'
      doi: 'https://doi.org/10.1145/3582700.3582708'
      time: '15:25 - 15:35'
    - title: 'Challenges in Virtual Reality Studies: Ethics and Internal and External Validity'
      authors: 'Sarah Delgado Rodriguez et al.'
      doi: 'https://doi.org/10.1145/3582700.3582716'
      time: '15:35 - 15:45'
    - title: 'Q&A'
      time: '15:45 - 16:00'

  - session: "Session 3: Human Empowerment"
    papers:
    - title: 'Effects of Wearing Knee-tightening Devices and Presenting Shear Forces to the Knee on Redirected Walking'
      authors: 'Gaku Fukui et al.'
      doi: 'https://doi.org/10.1145/3582700.3582720'
      time: '9:00 - 9:15'
    - title: 'LUNAChair: Remote Wheelchair System Linking Users to Nearby People and Assistants'
      authors: 'Luna Takagi et al.'
      doi: 'https://doi.org/10.1145/3582700.3582714'
      time: '9:15 - 9:30'
    - title: 'Visuospatial abilities and cervical spine range of motion improvement effects of a non-goal-oriented VR travel program at an older adults facility:A pilot randomized controlled trial'
      authors: 'Atsushi Hiyama et al.'
      doi: 'https://doi.org/10.1145/3582700.3582715'
      time: '9:30 - 9:45'
    - title: 'Exploration of Sonification Feedback for People with Visual Impairment to Use Ski Simulator'
      authors: 'Yusuke Miura et al.'
      doi: 'https://doi.org/10.1145/3582700.3582702'
      time: '9:45 - 10:00'
    - title: 'DecluttAR: An Interactive Visual Clutter Dimming System to Help Focus on Work'
      authors: 'Kaito Yokoro et al.'
      doi: 'https://doi.org/10.1145/3582700.3582718'
      time: '10:00 - 10:15'
    - title: 'ShadowClones: an Interface to Maintain a Multiple Sense of Body-space Coordination in Multiple Visual Perspectives'
      authors: 'Kazuma Takada et al.'
      doi: 'https://doi.org/10.1145/3582700.3582706'
      time: '10:15 - 10:30'
    - title: 'Q&A'
      time: '10:30 - 10:45'

  - session: "Session 4: Intelligence Augmentation"
    papers:
    - title: 'AI Coach: A Motor Skill Training System using Motion Discrepancy Detection'
      authors: 'Chen-Chieh Liao et al.'
      doi: 'https://doi.org/10.1145/3582700.3582710'
      time: '11:30 - 11:45'
    - title: 'CC-Glasses: Color Communication Support for People with Color Vision Deficiency Using Augmented Reality and Deep Learning'
      authors: 'Xiaoyang Mao et al.'
      doi: 'https://doi.org/10.1145/3582700.3582707'
      time: '11:45 - 12:00'
    - title: 'AIx speed: Playback Speed Optimization using Listening Comprehension of Speech Recognition Models'
      authors: 'Kazuki Kawamura et al.'
      doi: 'https://doi.org/10.1145/3582700.3582722'
      time: '12:00 - 12:15'
    - title: 'Exoskeleton for the Mind: Exploring Strategies Against Misinformation with a Metacognitive Agent'
      authors: 'Yeongdae Kim et al.'
      doi: 'https://doi.org/10.1145/3582700.3582725'
      time: '12:15 - 12:30'
    - title: 'Investigating Effects of Facial Self-Similarity Levels on the Impression of Virtual Agents in Serious/Non-Serious Contexts'
      authors: 'Masayasu Niwa et al.'
      doi: 'https://doi.org/10.1145/3582700.3582721'
      time: '12:30 - 12:45'
    - title: 'Q&A'
      time: '12:45 - 13:00'

  - session: "Session 5: Interfaces for the Body and Beyond"
    papers:
    - title: 'Affective Umbrella -- A Wearable System to Visualize Heart and Electrodermal Activity, towards Emotion Regulation through Somaesthetic Appreciation'
      authors: 'Kanyu Chen et al.'
      doi: 'https://doi.org/10.1145/3582700.3582727'
      time: '14:15 - 14:30'
    - title: 'TOMURA: A Mountable Hand-shaped Interface for Versatile Interactions'
      authors: 'Shigeo Yoshida et al.'
      doi: 'https://doi.org/10.1145/3582700.3582719'
      time: '14:30 - 14:45'
    - title: 'DUMask: A Discrete and Unobtrusive Mask-Based Interface for Facial Gestures'
      authors: 'Arpit Bhatia et al.'
      doi: 'https://doi.org/10.1145/3582700.3582726'
      time: '14:45 - 15:00'
    - title: 'Dynamic Derm: Body Surface Deformation Display for Real-World Embodied Interactions'
      authors: 'Ryo Murata et al.'
      doi: 'https://doi.org/10.1145/3582700.3582723'
      time: '15:00 - 15:15'
    - title: 'Human Coincident Robot: A Non-contact Surrounding Robot Sharing the Coordinate with a Human Inside'
      authors: 'Takafumi Watanabe et al.'
      doi: 'https://doi.org/10.1145/3582700.3582724'
      time: '15:15 - 15:30'
    - title: 'Q&A'
      time: '15:30 - 15:45'



# session-title: Session Schedules
# session: |
#   <h3 style="color: black;">Session 1: Haptic Feedback</h3>
#   <table id="sessions">
#   <tr>
#     <th>Time</th>
#     <th>Paper</th> 
#   </tr>
#   <tr>
#     <td>11:30 - 11:45</td>
#     <td>
#     S78: Designing Interactive Shoes for Tactile Augmented Reality
#     <p class="authors">Test</p>
#     <p class="doi"></p>
#     </td> 
#   </tr>
#   <tr>
#     <td>11:45 - 12:00</td>
#     <td>S15: GAuze-MIcrosuture-FICATION: Gamification in Microsuture training with real-time feedback</td> 
#   </tr>
#   <tr>
#     <td>12:00 - 12:15</td>
#     <td>S32: Standing Balance Improved by Electrical Muscle Stimulation to Popliteus Muscles</td> 
#   </tr>
#   <tr>
#     <td>12:15 - 12:30</td>
#     <td>S5: Tactile Vectors for Omnidirectional Arm Guidance</td> 
#   </tr>
#   <tr>
#     <td>12:30 - 12:45</td>
#     <td>S38: Coldness Presentation to Ventral Forearm using Electrical Stimulation with Elastic Gel and Anesthetic Cream</td> 
#   </tr>
#   <tr>
#     <td>12:45 - 13:00</td>
#     <td>Q&A</td> 
#   </tr>
#   </table>

#   <h3 style="color: black;">Session 2: Perception and Extended Reality</h3>
#   <table id="sessions">
#   <tr>
#     <th>Time</th>
#     <th>Paper</th> 
#   </tr>
#   <tr>
#     <td>14:15 - 14:30</td>
#     <td>S30: Virtual Omnibus Lecture: Investigating the Effects of Varying Lecturer Avatars as Environmental Context on Audience Memory</td> 
#   </tr>
#   <tr>
#     <td>14:30 - 14:45</td>
#     <td>S36: LocatAR: An AR Object Search Assistance System for a Shared Space</td> 
#   </tr>
#   <tr>
#     <td>14:45 - 15:00</td>
#     <td>S16: Generation of realistic facial animation of a CG avatar speaking a moraic language</td> 
#   </tr>
#   <tr>
#     <td>15:00 - 15:15</td>
#     <td>S12: Effect of Weight Adjustment in Virtual Co-embodiment During Collaborative Training</td> 
#   </tr>
#   <tr>
#     <td>15:15 - 15:25</td>
#     <td>S43: Workspace Scaling in Virtual Reality based Robot Teleoperation</td> 
#   </tr>
#   <tr>
#     <td>15:25 - 15:35</td>
#     <td>S22: Tablet Cutting Board: Tablet-based Knife-control Learning Support System for Cookery Beginners</td> 
#   </tr>
#   <tr>
#     <td>15:35 - 15:45</td>
#     <td>S42: Challenges in Virtual Reality Studies: Ethics and Internal and External Validity</td> 
#   </tr>
#   <tr>
#     <td>15:45 - 16:00</td>
#     <td>Q&A</td> 
#   </tr>
#   </table>

#   <h3 style="color: black;">Session 3: Human Empowerment</h3>
#   <table id="sessions">
#   <tr>
#     <th>Time</th>
#     <th>Paper</th> 
#   </tr>
#   <tr>
#     <td>9:00 - 9:15</td>
#     <td>S58: Effects of Wearing Knee-tightening Devices and Presenting Shear Forces to the Knee on Redirected Walking</td> 
#   </tr>
#   <tr>
#     <td>9:15 - 9:30</td>
#     <td>S39: LUNAChair: Remote Wheelchair System Linking Users to Nearby People and Assistants</td> 
#   </tr>
#   <tr>
#     <td>9:30 - 9:45</td>
#     <td>S40: Visuospatial abilities and cervical spine range of motion improvement effects of a non-goal-oriented VR travel program at an older adults facility:A pilot randomized controlled trial</td> 
#   </tr>
#   <tr>
#     <td>9:45 - 10:00</td>
#     <td>S8: Exploration of Sonification Feedback for People with Visual Impairment to Use Ski Simulator</td> 
#   </tr>
#   <tr>
#     <td>10:00 - 10:15</td>
#     <td>S44: DecluttAR: An Interactive Visual Clutter Dimming System to Help Focus on Work</td> 
#   </tr>
#   <tr>
#     <td>10:15 - 10:30</td>
#     <td>S18: ShadowClones: an Interface to Maintain a Multiple Sense of Body-space Coordination in Multiple Visual Perspectives</td> 
#   </tr>
#   <tr>
#     <td>10:30 - 10:45</td>
#     <td>Q&A</td> 
#   </tr>
#   </table>

#   <h3 style="color: black;">Session 4: Intelligence Augmentation</h3>
#   <table id="sessions">
#   <tr>
#     <th>Time</th>
#     <th>Paper</th> 
#   </tr>
#   <tr>
#     <td>11:30 - 11:45</td>
#     <td>S31: AI Coach: A Motor Skill Training System using Motion Discrepancy Detection</td> 
#   </tr>
#   <tr>
#     <td>11:45 - 12:00</td>
#     <td>S20: CC-Glasses: Color Communication Support for People with Color Vision Deficiency Using Augmented Reality and Deep Learning</td> 
#   </tr>
#   <tr>
#     <td>12:00 - 12:15</td>
#     <td>S64: AIx speed: Playback Speed Optimization using Listening Comprehension of Speech Recognition Models</td> 
#   </tr>
#   <tr>
#     <td>12:15 - 12:30</td>
#     <td>S70: Exoskeleton for the Mind: Exploring Strategies Against Misinformation with a Metacognitive Agent</td> 
#   </tr>
#   <tr>
#     <td>12:30 - 12:45</td>
#     <td>S63: Investigating Effects of Facial Self-Similarity Levels on the Impression of Virtual Agents in Serious/Non-Serious Contexts</td> 
#   </tr>
#   <tr>
#     <td>12:45 - 13:00</td>
#     <td>Q&A</td> 
#   </tr>
#   </table>

#   <h3 style="color: black;">Session 5: Interfaces for the Body and Beyond</h3>
#   <table id="sessions">
#   <tr>
#     <th>Time</th>
#     <th>Paper</th> 
#   </tr>
#   <tr>
#     <td>14:15 - 14:30</td>
#     <td>S74: Affective Umbrella -- A Wearable System to Visualize Heart and Electrodermal Activity, towards Emotion Regulation through Somaesthetic Appreciation</td> 
#   </tr>
#   <tr>
#     <td>14:30 - 14:45</td>
#     <td>S53: TOMURA: A Mountable Hand-shaped Interface for Versatile Interactions</td> 
#   </tr>
#   <tr>
#     <td>14:45 - 15:00</td>
#     <td>S71: DUMask: A Discrete and Unobtrusive Mask-Based Interface for Facial Gestures</td> 
#   </tr>
#   <tr>
#     <td>15:00 - 15:15</td>
#     <td>S67: Dynamic Derm: Body Surface Deformation Display for Real-World Embodied Interactions</td> 
#   </tr>
#   <tr>
#     <td>15:15 - 15:30</td>
#     <td>S68: Human Coincident Robot: A Non-contact Surrounding Robot Sharing the Coordinate with a Human Inside</td> 
#   </tr>
#   <tr>
#     <td>15:30 - 15:45</td>
#     <td>Q&A</td> 
#   </tr>
#   </table>

keynote-title: 'Keynote: Florian Alt'
keynote: |
  <h3 style="color:#003865;">Behavior and Physiology-Aware Security User Interfaces</h3>
  <strong>Abstract:</strong> Over the past years a global and highly professional cybercrime industry has established itself, making user-centred attacks an omnipresent threat for society. Companies, organisations, and individuals struggle to keep up and protect themselves effectively from an ever-growing number of sophisticated attack vectors. Reasons are, among others, a general lack of awareness and understanding of such threats, inherently complex and difficult-to-understand security and privacy mechanisms, and users struggling to habituate secure behavior in cyber space. Yet, humans are not as helpless as it seems, as many examples of secure behavior in the real world demonstrate. We naturally lock doors, we place valuables in safes or lockers, and we take small detour at night rather than walking through dark areas and parks. Based on examples from our research, I will demonstrate how such natural behavior can be supported in the digital world through the design and development of security user interfaces that are aware of human behavior and physiology. I will showcase how technologies for human augmentation allow a detailed understanding on humans’ responses to security-related situations to be obtained and leveraged so as to target opportune moments, enable contextualised means for protection, and increase users’ security literacy.
keynote-author: |
  <strong>Florian Alt</strong>
  <strong>Short Bio:</strong> Florian Alt is a full professor of Usable Security and Privacy at the Research Institute for Cyber Defence (CODE) in Munich. In his work, he is interested in designing secure and privacy-preserving systems that naturally blend with the way in which users interact with computing devices. Florian’s research focuses on investigating users’ behavior in security contexts, on creating and enhancing security and privacy mechanisms based on users’ behavior and physiology, and on understanding as well as mitigating threats emerging from novel ubiquitous technologies. Specific areas of application are Mixed Reality, Smart Homes, and Social Engineering. Florian holds a diploma in Media Informatics from LMU Munich and a Ph.D. in Human-Computer Interaction from the University of Stuttgart.
keynote-short: |
  <h3 style="color:#003865;">Behavior and Physiology-Aware Security User Interfaces</h3>
keynote-author-short: |
  <strong>Florian Alt</strong> is a full professor of Usable Security and Privacy at the Research Institute for Cyber Defence (CODE) in Munich.
keynote-img: /img/keynote-speaker/florian_alt.jpg

# program-papers:
#   - Detecting Episodes of Increased Cough Using Kinetic Earables<br /><small>Tobias Röddiger, Michael Beigl, Michael Hefenbrock, Daniel Wolffram and Erik Pescara</small>
#   - Portable 3D Human Pose Estimation for Human-Human Interaction using a Chest-Mounted Fisheye Camera <br /><small>Kohei Aso, Dong-Hyun Hwang and Hideki Koike</small>
#   - CapGlasses&#58; Untethered Capacitive Sensing with Smart Glasses <br /><small>Denys J.C. Matthies, Chamod Weerasinghe, Suranga Nanayakkara and Bodo Urban</small>
#   - Exploratory Design of a Hands-free Video Game Controller for a Quadriplegic Individual <br /><small>Atieh Taheri and Misha Sra</small>
#   - Virtual Whiskers&#58; Spatial Directional Guidance using Cheek Haptic Stimulation in a Virtual Environment <br /><small>Fumihiko Nakamura, Adrien Verhulst, Kuniharu Sakurada and Maki Sugimoto</small>
#   - Wearable System for Promoting Salivation <br /><small>Kai Washino, Ayumi Ohnishi, Tsutomu Terada and Masahiko Tsukamoto</small>
#   - HemodynamicVR - Adapting the User's Field Of View during Virtual Reality Locomotion Tasks using Wearable Functional Near-Infrared Spectroscopy <br /><small>Hiroo Yamamura, Holger Baldauf and Kai Kunze</small>
#   - Augmented Foot&#58; A Comprehensive Survey of Foot Augmentation Devices <br /><small>Don Samitha Elvitigala, Jochen Huber and Suranga Nanayakkara</small>
#   - Motion-specific Browsing method by mapping to a circle for personal video Observation with Head-Mounted Displays <br /><small>Natsuki Hamanishi and Jun Rekimoto</small>
#   - Exploring Pseudo Hand-Eye Interaction on the Head-Mounted Display <br /><small>Myung Jin Kim and Andrea Bianchi</small>
#   - MultiSoma&#58; Distributed Embodiment with Synchronized Behavior and Perception <br /><small>Reiji Miura, Maki Sugimoto, Shunichi Kasahara, Michiteru Kitazaki, Adrien Verhulst and Masahiko Inami</small>
#   - Dynamic Shared Limbs&#58; An Adaptive Shared Body Control Method Using EMG Sensors <br /><small>Ryo Takizawa, Takayoshi Hagiwara, Adrien Verhulst, Masaaki Fukuoka, Michiteru Kitazaki and Maki Sugimoto</small>
#   - Independent Control of Supernumerary Appendages Exploiting Upper Limb Redundancy <br /><small>Hideki Shimobayashi, Tomoya Sasaki, Arata Horie, Riku Arakawa, Zendai Kashino and Masahiko Inami</small>
#   - Research on the transcendence of bodily differences, using sport and human augmentation medium <br /><small>Ryoichi Ando, Isao Uebayashi, Hayato Sato, Hayato Ohbayashi, Shota Katagiri, Shuhei Hayakawa and Kouta Minamizawa</small>
#   - SilentMask&#58; Mask-type Silent Speech Interface with Measurement of Mouth Movement <br /><small>Hirotaka Hiraki and Jun Rekimoto</small>
#   - Derma&#58; Silent Speech Interaction Using Transcutaneous MotionSensing <br /><small>Jun Rekimoto and Yui Nishimura</small>
#   - Conversational Partner’s Perception of Subtle Display Use for Monitoring Notifications <br /><small>Jacob Logas, Kelsie Belan, Thad Starner and Blue Lin</small>
#   - Deep Learning-Based Scene Simplification for Bionic Vision <br /><small>Nicole Han, Sudhanshu Srivastava, Aiwen Xu, Devi Klein and Michael Beyeler</small>
#   - FaceRecGlasses&#58; A Wearable System for Recognizing Self Facial Expression Using Compact Wearable Cameras <br /><small>Hiroaki Aoki, Ayumi Ohnishi, Naoya Isoyama, Tsutomu Terada and Masahiko Tsukamoto</small>
#   - CircadianVisor&#58; Image Presentation With an Optical See-Through Display in Consideration of Circadian Illuminance <br /><small>Takumi Tochimoto, Yuichi Hiroi and Yuta Itoh</small>
#   - Advantage and Misuse of Vision Augmentation - Exploring User Perceptions and Attitudes using a Zoom Prototype <br /><small>Chloe Eghtebas, Francisco Kiss, Marion Koelle and Paweł Woźniak</small>
#   - SmartAidView Jacket&#58; Providing visual aid to lower the underestimation of assistive forces <br /><small>Swagata Das, Velika Wongchadakul and Yuichi Kurita</small>
#   - Virtual Physical Task Training&#58; Comparing Shared Body, Shared View and Verbal Task Explanation <br /><small>Jens Reinhardt, Marco Kurzweg and Katrin Wolf</small>
#   - Hippocampal Cognitive Prosthesis, Memory and Identity&#58; Case Study for the Role of Ethics Guidelines for Human Enhancement <br /><small>Yasemin J. Erden and Philip Brey</small>
#   - CV-Based Analysis for Microscopic Gauze Suturing Training <br /><small>Mikihito Matsuura, Shio Miyafuji, Erwin Wu, Satoshi Kiyofuji, Taichi Kin, Takeo Igarashi and Hideki Koike</small>
#   - A Machine Learning Model Perceiving Brightness Optical Illusions&#58; Quantitative Evaluation with Psychophysical Data <br /><small>Yuki Kubota, Atsushi Hiyama and Masahiko Inami</small>
#   - POV Display and Interaction Methods extending Smartphone <br /><small>Yura Tamai, Maho Oki and Koji Tsukada</small>
#   - From Strangers to Friends&#58; Augmenting Face-to-face Interactions with Faceted Digital Self-Presentations <br /><small>Mikko Kytö, Ilyena Hirskyj-Douglas and David McGookin</small>
#   - Interactive Eye Aberration Correction for Holographic Near-Eye Display <br /><small>Kenta Yamamoto, Ippei Suzuki, Kosaku Namikawa, Kaisei Sato and Yoichi Ochiai</small>
#   - Ubiquitous Body&#58; Effect of Spatial Arrangement of Task’s View on Managing Multiple Tasks<br <br/><small>Yukiko Iwasaki and Hiroyasu Iwata</small>


# keynote-title: Keynotes
# keynotes:

# - speaker: Prof. Thad Starner
#   Title: Augmenting human animal communication
#   image: /img/keynote-speaker/thad_starner_0.png
#   Abstract: Animals perceive much more than they can communicate with humans. For example, service dogs can sense when their handlers are about to fall victim to insulin shock. Bomb sniffing dogs can tell the difference between c4 and a peroxide bomb. Pods of dolphins have complex social structures and even refer to each other by name. Over the past decade, we have investigated how to use computer interfaces to help bridge the gap between animal and human communication. In this talk we will discuss some of the more practical use cases for what we have discovered.
#   Biography: Thad Starner is a Professor at the Georgia Institute of Technology's School of Interactive Computing. Thad was perhaps the first to integrate a wearable computer into his everyday life as an intelligent personal assistant. Starner's work as a PhD student would help found the field of Wearable Computing. 

# - speaker: Pattie Maes
#   Title: TBA
#   image: /img/keynote-speaker/pattie_maes.png
#   Biography: Pattie Maes is a professor in MIT's Program in Media Arts and Sciences and until recently served as academic head. She runs the Media  Lab's Fluid Interfaces research group, which aims to radically reinvent the human-machine experience. Coming from a background in artificial intelligence and human-computer interaction, she is particularly interested in the topic of cognitive enhancement, or how immersive and wearable systems can actively assist people with memory, attention, learning, decision making, communication, and wellbeing. 
